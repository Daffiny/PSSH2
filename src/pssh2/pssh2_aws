#!/bin/bash

### runs pssh2 for a set of md5 sums
#$ -o /dev/null
#$ -e /dev/null

#set -x

if [ -z "$conf_file" ]; then
	conf_file='/etc/pssh2.conf'
fi

usage()
{
cat << EOT
NAME
  pssh2_aws - generate pssh2 type sequence-to-structrue alignments for many sequences on AWS
SYNOPSIS
  pssh2_aws [-h] [-D] [-- ...]
DESCRIPTION
  pssh2_aws runs until terminated externally.
  It (repeatedly) queries for md5 sums to process,
  for each md5 it
  - gets corresponding cache entries from S3,
  - gets the associated sequences from the database,
  - runs pssh2_seq (which adds the alignment to the database),
  - stores the result files in S3.
  If there are no md5 sums to process, it sleeps for a radom time.
  See pssh2_seq -h for more details on pssh2_seq.
  Defaults are configured in $conf_file.
OPTIONS
  -h          The option -h displays help and exits.
  -D          Debug option: do not remove or zip output files (passed on to pssh2_seq)
  Any other parameters behind "--" are passed on to the child scripts.
AUTHOR
  Andrea Schafferhans <andrea.schafferhans@rostlab.org>
EOT
}


### base path to cache
pssh2_cache="/mnt/data/pssh_cache/"
### work directory
temp_work="/mnt/data/tmp/pssh2"
### table to store pssh2 calculation status in
status_table="pssh2_active_counts"

# get configurable options, e.g. local file paths
if [ -s $conf_file ]
then
	source $conf_file
fi

debug=0
passOpt=" " 
while getopts :Dhm: opt
do
	case $opt in
	D) debug=1; passOpt="$passOpt -$opt";; 
	h) usage; echo " "; pssh2_seq -h; exit;;
#	m) md5list=$OPTARG;;
#	*) passOpt="$passOpt $OPTARG";;
	esac
done

if [ $debug -eq 1 ]
then
	set -x
fi

shift $(expr $OPTIND - 1 )
passOpt="$passOpt $@"
get_seq=0

REGION=`wget -q 169.254.169.254/latest/meta-data/placement/availability-zone -O- | sed 's/.$//'`
ACCOUNT=`wget -q 169.254.169.254/latest/dynamic/instance-identity/document -O- | grep accountId | awk -F'"' '{print $4}'`

cd $temp_work

while true 
do
	
	# get the next md5 to process
	# We receive a message (with the next md5 sum) which then gets hidden from other workers for one hour 
    # (so that the md5 is not processed multiple times). 
    # The call to aws is delayed up to 20 seconds (to give AWS infrastructure time to look 
    # for messages in case none is readily available at the query endpoint). 
    # Unused messages (= md5 sums) will be discarded automatically after two weeks 
  	# (when no worker has taken care of them).
	MSG=`aws --region=$REGION sqs receive-message --queue-url https://sqs.$REGION.amazonaws.com/$ACCOUNT/aquaria-small --query 'Messages[*].[ReceiptHandle,Body]' --output text`
	HANDLE=`awk '{print $1}' <<< $MSG`
	md5=`awk '{print $2}' <<< $MSG`
	keepWorking=0	

	# if we really received something, we process, otherwise we poll again until we are killed
	if [ -n $md5 ]
	then
		keepWorking=1	
	fi
	
	# make sure we have a cache directory we can work in and get data from the cache
	if [ $keepWorking -eq 1 ]
	then
		# get subdir names for cache structure
		M=`echo $md5|cut -b1,2`
		M2=`echo $md5|cut -b3,4`

	### full path to cachedir
		CC="$pssh2_cache$M/$M2/$md5"
		mkdir -p $CC
		if [ -d $CC ] 
		then
			echo "working in $CC"
			# look for md5 in S3 and unpack
			if aws --region=$REGION s3 ls s3://aquaria-$ACCOUNT-$REGION/$md5 > /dev/null
			then
				cd $CC
				# gets the data under the tar directly into current directory
				aws --region=$REGION s3 cp s3://aquaria-$ACCOUNT-$REGION/$md5 - | tar -xz
				cd $temp_work
			fi
			keepWorking=1
		else 
			echo "ERROR: was not able to work on cache for $CC please go fix"
			# LATER: we should probably raise and error and die here (or below?)!
			keepWorking=0
			count=-999
		fi
	fi
	
	# make sure we have an input sequence
	if [ $keepWorking -eq 1 ]
	then
		input_seq_file=$CC/query.fasta

		# check whether an input file already exists in $CC
		if [ -s $input_seq_file ] 
		then
			old_md5=`cat $input_seq_file|fasta_to_md5`
			if  [ $old_md5 == $md5 ]
			then
				echo "working with old file $input_seq_file, with md5: $old_md5"
			else 
				get_seq=1
				echo "old file $input_seq_file, has different md5: $old_md5 -> retrieve again!"
			fi
		else
			get_seq=1
		fi

		if [ $get_seq -eq 1 ]
		then 
			temp_fasta_file=`get_fasta_for_md5 $md5`
			if [ -s $temp_fasta_file ]
			then	
				cp $temp_fasta_file $input_seq_file
			else 
				echo "ERROR: didn't get the sequence for $md5"
			fi
		fi		

		if [ -s $input_seq_file ] 
		then
			keepWorking=1
		else
			keepWorking=0
			count=-99
		fi
	fi

	# now we have prepared everything, we can actually do the work
	if [ $keepWorking -eq 1 ]
	then
		cd $CC
#		pwd
#		ls -lahtr
		pssh2_seq $passOpt
		# evaluate return state of pssh2_seq for messaging the queue? 
		count=`DB.pssh2_local "select * from pssh2_local.$status_table where md5=\"$md5\"" | tail -n +2 | cut -f 2`
			
		# pack directory and write to S3
		tar -cz * | aws --region=$REGION s3 cp - s3://aquaria-$ACCOUNT-$REGION/$MD5
#		tar -c /mnt/data/pssh2_cache/`sed 's/\(..\).*/\1/'<<<$MD5`/`sed 's/..\(..\).*/\1/'<<<$MD5`/$MD5 | aws --region=$REGION s3 cp - s3://aquaria-$ACCOUNT-$REGION/$MD5
		cd $temp_work
	else 
		# if we didn't do anything, we need to store the info about that failure in the database
		s=`date +%s`
		DB.pssh2_local "insert into pssh2_local.$status_table set md5=\"$md5\" , count=$count, stamp=$s , runtime=$SECONDS" 
		echo "ERROR: could not find sequence: $input_seq_file or $temp_fasta_file"
	fi

	# send the queue a message that this sequence has been processed
	# if the count is -999 the compute node had a problem with the cache
	# if the count is -99 the sequence has a problem
	# if the count is -3 then no structures had been found (no pssh2 file generated)
	# if the count is -2 then scanning structures had failed -> try rerun with more memory
	# if the count is -1 then building the hmm had failed -> try rerun with more memory

	finished=0
	redo_large=0
	if [ $count -gt -1 ]
	then 
		finished=1
	elif [ $count -eq -1 ]
	then
		redo_large=1
	elif [ $count -eq -2 ]
	then
		redo_large=1
	else
		finished=1
		# LATER: possibly write some log messages about failures?
	fi
		
	if [ $redo_large -eq 1 ]
	then
# 		submit to another queue before we tell this one we are done?
#		aws ...  #	LATER : add to another queue!
		finished=1
	fi
	
	if [ $finished -eq 1 ]
	then
		aws --region=$REGION sqs delete-message --queue-url https://sqs.$REGION.amazonaws.com/$ACCOUNT/aquaria-small --receipt-handle $HANDLE
	fi

	# reset the variables so don't accidentally use them again
	md5=""
	HANDLE=""
	
done

